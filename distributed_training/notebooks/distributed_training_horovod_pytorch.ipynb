{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Pytorch training using Horovod via OCI Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "1. [Train](#Train)\n",
    "1. [Setup IAM](#Setup%20IAM)\n",
    "1. [Build](#Build)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "Horovod is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and MXNet. This notebook example shows how to use Horovod with Pytorch in OCI Data Science Jobs. OCI Data Science currently support Elastic Horovod workloads with gloo backend.\n",
    "\n",
    "For more information about the Horovod with Pytorch , please visit [Horovod-Pytorch](https://horovod.readthedocs.io/en/stable/pytorch.html)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install ads package >= 2.5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install oracle-ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Install docker:\n",
    "\n",
    "https://docs.docker.com/get-docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Set IAM Policies\n",
    "\n",
    "Following Policies need to be in place in the OCI IAM service. This would allow OCI datascience job runs to access needed services such as logging, object storage, vcns etc.\n",
    "\n",
    "#### Create the Dynamic Group\n",
    "```\n",
    "ALL {resource.type = ‘datasciencejobrun’, resource.compartment.id = <COMPARTMENT_OCID>}\n",
    "```\n",
    "\n",
    "#### Create policies\n",
    "```\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to use log-content in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to use log-groups in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to inspect repos in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to inspect vcns in compartment <COMPARTMENT_NAME>\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to manage objects in compartment <COMPARTMENT_NAME> where any {target.bucket.name='<BUCKET_NAME>'}\n",
    "Allow dynamic-group <DYNAMIC_GROUP_NAME> to manage buckets in compartment <COMPARTMENT_NAME> where any {target.bucket.name='<BUCKET_NAME>'}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Create VCN and private subnet\n",
    "\n",
    "Horovod Distributed Training requires nodes to communicate to each other. Therefor, network settings need to be provisioned. Create a VCN and a private subnet. Ths subnet id of this private subnet needs to be configured in the workload yaml file ('train.yaml')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainining Script\n",
    "\n",
    "This section will create a horovod pytorch training script. This is the training code that executes on the horovod cluster. The script must confirm to Elastic Horovod apis.\n",
    "\n",
    "The following script uses Horovod framework for distributed training where Horovod related apis are commented starting with `Horovod:`. <br> For example, `Horovod: add Horovod DistributedOptimizer`, `Horovod: initialize optimize`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "# Script adapted from https://github.com/horovod/horovod/blob/master/examples/elastic/pytorch/pytorch_mnist_elastic.py\n",
    "\n",
    "# ==============================================================================\n",
    "import argparse\n",
    "import os\n",
    "from filelock import FileLock\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.utils.data.distributed\n",
    "import horovod.torch as hvd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                    help='input batch size for training (default: 64)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                    help='input batch size for testing (default: 1000)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                    help='SGD momentum (default: 0.5)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
    "                    help='random seed (default: 42)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--fp16-allreduce', action='store_true', default=False,\n",
    "                    help='use fp16 compression during allreduce')\n",
    "parser.add_argument('--use-adasum', action='store_true', default=False,\n",
    "                    help='use adasum algorithm to do reduction')\n",
    "parser.add_argument('--data-dir',\n",
    "                    help='location of the training dataset in the local filesystem (will be downloaded if needed)')\n",
    "\n",
    "args = parser.parse_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "checkpoint_format = 'checkpoint-{epoch}.pth.tar'\n",
    "\n",
    "# Horovod: initialize library.\n",
    "hvd.init()\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if args.cuda:\n",
    "    # Horovod: pin GPU to local rank.\n",
    "    torch.cuda.set_device(hvd.local_rank())\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "# Horovod: limit # of CPU threads to be used per worker.\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
    "data_dir = args.data_dir or './data'\n",
    "with FileLock(os.path.expanduser(\"~/.horovod_lock\")):\n",
    "    train_dataset = \\\n",
    "        datasets.MNIST(data_dir, train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "# Horovod: use DistributedSampler to partition the training data.\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    train_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs)\n",
    "\n",
    "test_dataset = \\\n",
    "    datasets.MNIST(data_dir, train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ]))\n",
    "# Horovod: use DistributedSampler to partition the test data.\n",
    "test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "    test_dataset, num_replicas=hvd.size(), rank=hvd.rank())\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size,\n",
    "                                          sampler=test_sampler, **kwargs)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# By default, Adasum doesn't need scaling up learning rate.\n",
    "lr_scaler = hvd.size() if not args.use_adasum else 1\n",
    "\n",
    "if args.cuda:\n",
    "    # Move model to GPU.\n",
    "    model.cuda()\n",
    "    # If using GPU Adasum allreduce, scale learning rate by local_size.\n",
    "    if args.use_adasum and hvd.nccl_built():\n",
    "        lr_scaler = hvd.local_size()\n",
    "\n",
    "# Horovod: scale learning rate by lr_scaler.\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr * lr_scaler,\n",
    "                      momentum=args.momentum)\n",
    "\n",
    "# Horovod: (optional) compression algorithm.\n",
    "compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n",
    "\n",
    "\n",
    "def metric_average(val, name):\n",
    "    tensor = torch.tensor(val)\n",
    "    avg_tensor = hvd.allreduce(tensor, name=name)\n",
    "    return avg_tensor.item()\n",
    "\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "# Horovod: average metrics from distributed training.\n",
    "class Metric(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.sum = torch.tensor(0.)\n",
    "        self.n = torch.tensor(0.)\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += hvd.allreduce(val.detach().cpu(), name=self.name)\n",
    "        self.n += 1\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        return self.sum / self.n\n",
    "\n",
    "@hvd.elastic.run\n",
    "def train(state):\n",
    "    # post synchronization event (worker added, worker removed) init ...\n",
    "\n",
    "    artifacts_dir = os.environ.get(\"OCI__SYNC_DIR\") + \"/artifacts\"\n",
    "    chkpts_dir = os.path.join(artifacts_dir,\"ckpts\")\n",
    "    logs_dir = os.path.join(artifacts_dir,\"logs\")\n",
    "    if hvd.rank() == 0:\n",
    "        print(\"creating dirs for checkpoints and logs\")\n",
    "        create_dir(chkpts_dir)\n",
    "        create_dir(logs_dir)\n",
    "\n",
    "    writer = SummaryWriter(logs_dir) if hvd.rank() == 0 else None\n",
    "\n",
    "    for state.epoch in range(state.epoch, args.epochs + 1):\n",
    "        train_loss = Metric('train_loss')\n",
    "        state.model.train()\n",
    "\n",
    "        train_sampler.set_epoch(state.epoch)\n",
    "        steps_remaining = len(train_loader) - state.batch\n",
    "\n",
    "        for state.batch, (data, target) in enumerate(train_loader):\n",
    "            if state.batch >= steps_remaining:\n",
    "                break\n",
    "\n",
    "            if args.cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            state.optimizer.zero_grad()\n",
    "            output = state.model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            train_loss.update(loss)\n",
    "            loss.backward()\n",
    "            state.optimizer.step()\n",
    "            if state.batch % args.log_interval == 0:\n",
    "                # Horovod: use train_sampler to determine the number of examples in\n",
    "                # this worker's partition.\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    state.epoch, state.batch * len(data), len(train_sampler),\n",
    "                    100.0 * state.batch / len(train_loader), loss.item()))\n",
    "            state.commit()\n",
    "        if writer:\n",
    "           writer.add_scalar(\"Loss\", train_loss.avg, state.epoch)\n",
    "        if hvd.rank() == 0:\n",
    "            chkpt_path = os.path.join(chkpts_dir,checkpoint_format.format(epoch=state.epoch + 1))\n",
    "            chkpt = {\n",
    "                'model': state.model.state_dict(),\n",
    "                'optimizer': state.optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(chkpt, chkpt_path)\n",
    "        state.batch = 0\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0.\n",
    "    test_accuracy = 0.\n",
    "    for data, target in test_loader:\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        test_accuracy += pred.eq(target.data.view_as(pred)).cpu().float().sum()\n",
    "\n",
    "    # Horovod: use test_sampler to determine the number of examples in\n",
    "    # this worker's partition.\n",
    "    test_loss /= len(test_sampler)\n",
    "    test_accuracy /= len(test_sampler)\n",
    "\n",
    "    # Horovod: average metric values across workers.\n",
    "    test_loss = metric_average(test_loss, 'avg_loss')\n",
    "    test_accuracy = metric_average(test_accuracy, 'avg_accuracy')\n",
    "\n",
    "    # Horovod: print output only on first rank.\n",
    "    if hvd.rank() == 0:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n",
    "            test_loss, 100. * test_accuracy))\n",
    "\n",
    "\n",
    "# Horovod: wrap optimizer with DistributedOptimizer.\n",
    "optimizer = hvd.DistributedOptimizer(optimizer,\n",
    "                                     named_parameters=model.named_parameters(),\n",
    "                                     compression=compression,\n",
    "                                     op=hvd.Adasum if args.use_adasum else hvd.Average)\n",
    "\n",
    "\n",
    "# adjust learning rate on reset\n",
    "def on_state_reset():\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = args.lr * hvd.size()\n",
    "\n",
    "\n",
    "state = hvd.elastic.TorchState(model, optimizer, epoch=1, batch=0)\n",
    "state.register_reset_callbacks([on_state_reset])\n",
    "train(state)\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build\n",
    "\n",
    "### Initialize a distributed-training folder\n",
    "Next step would be to create a distributed-training workspace. Execute the following command to fetch the 'horovod-pytorch' framework. This would create a directory 'oci_dist_training_artifacts'. The directory essentially contains artifacts(dockerfile, configurations, gloo code etc) to build a horovod job docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ads opctl distributed-training init --framework horovod-pytorch --version v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME='hvdjob-cpu-pytorch'\n",
    "IMAGE_TAG=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -f oci_dist_training_artifacts/horovod/v1/docker/pytorch.cpu.Dockerfile -t $IMAGE_NAME:$IMAGE_TAG ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training code('train.py') is assumed to be in the current working directory. This can be overwritten using the 'CODE_DIR' build arg.\n",
    "\n",
    "`docker build --build-arg CODE_DIR=<code_folder> -f oci_dist_training_artifacts/horovod/docker/pytorch.cpu.Dockerfile -t $IMAGE_NAME:$IMAGE_TAG .`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the Docker Image to your Tenancy OCIR\n",
    "Steps\n",
    "1. Follow the instructions to setup container registry from [here](https://docs.oracle.com/en-us/iaas/Content/Registry/Tasks/registrypushingimagesusingthedockercli.htm)\n",
    "2. Make sure you create a repository in OCIR to push the image\n",
    "3. Tag Local Docker image that needs to be pushed. \n",
    "4. Push the Docker image from your machine to OCI Container Registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag Docker image\n",
    "Please replace the TENANCY_NAMESPACE (you can find this in tenancy information on oci console) and REGION_CODE [iad|phx ..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag $IMAGE_NAME:$IMAGE_TAG iad.ocir.io/<TENANCY_NAMESPACE>/horovod:$IMAGE_NAME:$IMAGE_TAG\n",
    "\n",
    "# Example: !docker tag $IMAGE_NAME:$IMAGE_TAG iad.ocir.io/ociodscdev/horovod/$IMAGE_NAME:$IMAGE_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push <REGION_CODE>.ocir.io/<TENANCY_NAMESPACE>/horovod/$IMAGE_NAME:$IMAGE_TAG\n",
    "\n",
    "#Example: !docker push iad.ocir.io/ociodscdev/horovod/$IMAGE_NAME:$IMAGE_TAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define your workload yaml:\n",
    "\n",
    "The yaml file is a declarative way to express the workload.\n",
    "Create a workload yaml file called `train.yaml` to specify the run config.\n",
    "\n",
    "Workload yaml file has the following format.\n",
    "<br>\n",
    "\n",
    "```yaml\n",
    "kind: distributed\n",
    "apiVersion: v1.0\n",
    "spec:\n",
    "  infrastructure: # This section maps to Job definition. Does not include environment variables\n",
    "    kind: infrastructure\n",
    "    type: dataScienceJob\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      projectId: oci.xxxx.<project_ocid>\n",
    "      compartmentId: oci.xxxx.<compartment_ocid>\n",
    "      displayName: HVD-Distributed-PYTORCH\n",
    "      logGroupId: oci.xxxx.<log_group_ocid>\n",
    "      logId: oci.xxx.<log_ocid>\n",
    "      subnetId: oci.xxxx.<subnet-ocid>\n",
    "      shapeName: VM.Standard2.4\n",
    "      blockStorageSize: 50\n",
    "  cluster:\n",
    "    kind: HOROVOD\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      image: \"iad.ocir.io/<tenancy_id>/<repo_name>/<image_name>:<image_tag>\"\n",
    "      workDir:  \"oci://<bucket_name>@<bucket_namespace>/<bucket_prefix>\"\n",
    "      name: \"horovod_pytorch\"\n",
    "      config:\n",
    "        env:\n",
    "          # MIN_NP, MAX_NP and SLOTS are inferred from the shape. Modify only when needed.\n",
    "          # - name: MIN_NP\n",
    "          #   value: 2\n",
    "          # - name: MAX_NP\n",
    "          #   value: 4\n",
    "          # - name: SLOTS\n",
    "          #   value: 2\n",
    "          - name: WORKER_PORT\n",
    "            value: 12345\n",
    "          - name: START_TIMEOUT #Optional: Defaults to 600.\n",
    "            value: 600\n",
    "          - name: ENABLE_TIMELINE # Optional: Disabled by Default.Significantly increases training duration if switched on (1).\n",
    "            value: 0\n",
    "          - name: SYNC_ARTIFACTS #Mandatory: Switched on by Default.\n",
    "            value: 1\n",
    "          - name: WORKSPACE #Mandatory if SYNC_ARTIFACTS==1: Destination object bucket to sync generated artifacts to.\n",
    "            value: \"<bucket_name>\"\n",
    "          - name: WORKSPACE_PREFIX #Mandatory if SYNC_ARTIFACTS==1: Destination object bucket folder to sync generated artifacts to.\n",
    "            value: \"<bucket_prefix>\"\n",
    "          - name: HOROVOD_ARGS # Parameters for cluster tuning.\n",
    "            value: \"--verbose\"\n",
    "      main:\n",
    "        name: \"scheduler\"\n",
    "        replicas: 1 #this will be always 1\n",
    "      worker:\n",
    "        name: \"worker\"\n",
    "        replicas: 2 #number of workers\n",
    "  runtime:\n",
    "    kind: python\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      entryPoint: \"/code/train.py\" #location of user's training script in docker image.\n",
    "      args:  #any arguments that the training script requires.\n",
    "      env:\n",
    "```\n",
    "<br> <br>\n",
    "The following variables are tenancy specific that needs to be modified.\n",
    "\n",
    "| Variable | Description |\n",
    "| :-------- | :----------- |\n",
    "|compartmentId|OCID of the compartment where Data Science projects are created|\n",
    "|projectId|OCID of the project created in Data Science service|\n",
    "|subnetId|OCID of the subnet attached your Job|\n",
    "|logGroupId|OCID of the log group for JobRun logs|\n",
    "|image|Image from OCIR to be used for JobRuns|\n",
    "|workDir|URL to the working directory for opctl|\n",
    "|WORKSPACE|Workspace with the working directory to be used|\n",
    "|entryPoint|The script to be executed when launching the container|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.yaml\n",
    "\n",
    "kind: distributed\n",
    "apiVersion: v1.0\n",
    "spec:\n",
    "  infrastructure: # This section maps to Job definition. Does not include environment variables\n",
    "    kind: infrastructure\n",
    "    type: dataScienceJob\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      projectId: oci.xxxx.<project_ocid>\n",
    "      compartmentId: oci.xxxx.<compartment_ocid>\n",
    "      displayName: HVD-Distributed-PYTORCH\n",
    "      logGroupId: oci.xxxx.<log_group_ocid>\n",
    "      logId: oci.xxx.<log_ocid>\n",
    "      subnetId: oci.xxxx.<subnet-ocid>\n",
    "      shapeName: VM.Standard2.4\n",
    "      blockStorageSize: 50\n",
    "  cluster:\n",
    "    kind: HOROVOD\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      image: \"iad.ocir.io/<tenancy_id>/<repo_name>/<image_name>:<image_tag>\"\n",
    "      workDir:  \"oci://<bucket_name>@<bucket_namespace>/<bucket_prefix>\"\n",
    "      name: \"horovod_pytorch\"\n",
    "      config:\n",
    "        env:\n",
    "          # MIN_NP, MAX_NP and SLOTS are inferred from the shape. Modify only when needed.\n",
    "          # - name: MIN_NP\n",
    "          #   value: 2\n",
    "          # - name: MAX_NP\n",
    "          #   value: 4\n",
    "          # - name: SLOTS\n",
    "          #   value: 2\n",
    "          - name: WORKER_PORT\n",
    "            value: 12345\n",
    "          - name: START_TIMEOUT #Optional: Defaults to 600.\n",
    "            value: 600\n",
    "          - name: ENABLE_TIMELINE # Optional: Disabled by Default.Significantly increases training duration if switched on (1).\n",
    "            value: 0\n",
    "          - name: SYNC_ARTIFACTS #Mandatory: Switched on by Default.\n",
    "            value: 1\n",
    "          - name: WORKSPACE #Mandatory if SYNC_ARTIFACTS==1: Destination object bucket to sync generated artifacts to.\n",
    "            value: \"<bucket_name>\"\n",
    "          - name: WORKSPACE_PREFIX #Mandatory if SYNC_ARTIFACTS==1: Destination object bucket folder to sync generated artifacts to.\n",
    "            value: \"<bucket_prefix>\"\n",
    "          - name: HOROVOD_ARGS # Parameters for cluster tuning.\n",
    "            value: \"--verbose\"\n",
    "      main:\n",
    "        name: \"scheduler\"\n",
    "        replicas: 1 #this will be always 1\n",
    "      worker:\n",
    "        name: \"worker\"\n",
    "        replicas: 2 #number of workers\n",
    "  runtime:\n",
    "    kind: python\n",
    "    apiVersion: v1.0\n",
    "    spec:\n",
    "      entryPoint: \"/code/train.py\" #location of user's training script in docker image.\n",
    "      args:  #any arguments that the training script requires.\n",
    "      env:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ads opctl to create the cluster infrastructure and run the workload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dry Run To check the runtime configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ads opctl run -f train.yaml --dry-run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit the workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ads opctl run -f train.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would emit the following information about the job created and the job runs within.<br>\n",
    "`jobId: <job_id>`<br>\n",
    "`mainJobRunId: <scheduer_job_run_id>`<br>\n",
    "`workDir: oci://<bucket_name>@<bucket_namespace>/<bucket_prefix>`<br>\n",
    "`workerJobRunIds:`<br>\n",
    "`- <worker_1_jobrun_id>`<br>\n",
    "`- <worker_2_jobrun_id>`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitor logs\n",
    "You can monitor the logs emitted from the job runs using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ads jobs watch <jobrun_id>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "notice": "Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
